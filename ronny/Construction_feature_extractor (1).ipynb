{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWhReRJ_kV1r"
      },
      "source": [
        "# Prediction of Ransome Activity / Construction of the features extractor\n",
        "\n",
        "Rihem Mansri, Mohamed Issa, Mootez Dakhlaoui, Bourhan Dernayka, Joel Pascal Soffo, Ronny Tonato"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TO DO LIST:\n",
        "<br>\n",
        "Wrap all of this in a class\n",
        "<br>\n",
        "Make different tests to choose the best metrics and baseline model\n",
        "<br>\n",
        "Remark 1 : Here, I did the standard scale on the whole dataset, which could not be a good pratice. A better thing to do would be to split the dataset, \"transformer.fit_transform\" the training set and \"transformer.transform\" the test set. \n",
        "<br>\n",
        "Remark 2:\n",
        "<br>\n",
        "I did not encode the address column because 90% of the address are different, meaning there are only few repetitive addresses. Not sure it's necessary to encode(can be discussed). "
      ],
      "metadata": {
        "id": "RTHRdynqxbgf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###importing the libraries\n",
        "import os\n",
        "import warnings\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import boxcox\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pdb\n",
        "import datetime\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import accuracy_score, log_loss, plot_roc_curve, f1_score, precision_score, recall_score\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import matplotlib\n",
        "from prettytable import PrettyTable\n",
        "from pprint import pprint\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "### Dataset\n",
        "data = pd.read_csv(\"BitcoinHeistData.csv\")\n",
        "\n",
        "##converting days and years in a single columns(year/month/day)\n",
        "from datetime import date, datetime\n",
        "\n",
        "dat_temp = []\n",
        "for i in range(data.shape[0]):\n",
        "    aux = date.fromordinal(date(data['year'][i], 1, 1).toordinal() + data['day'][i]  - 1).strftime('%d/%m/%Y')\n",
        "    dat_temp.append(aux)\n",
        "data['time'] = dat_temp\n",
        "data['time'] = pd.to_datetime(data['time'])\n",
        "\n",
        "###Converting labels to binary\n",
        "data.loc[data['label'] != 'white', 'label'] = 1\n",
        "data.loc[data['label'] == 'white', 'label'] = 0\n",
        "Y = data.pop('label')\n",
        "\n",
        "###Deleting day and year columns(became useless)\n",
        "data.pop('day')\n",
        "data.pop('year')\n",
        "\n",
        "###Transformation of the data\n",
        "cnt_featnames = ['length', 'weight', 'count', 'looped', 'neighbors', 'income']\n",
        "date_featnames = ['time']\n",
        "\n",
        "from sklearn.base import TransformerMixin, BaseEstimator\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from pandas import Timestamp\n",
        "\n",
        "# First we create a scikit-learn encoder that computes \n",
        "#  the age in days of columns containing dates\n",
        "class AgeEncoder(TransformerMixin, BaseEstimator):\n",
        "    def fit(self, X, y=None):\n",
        "        self.today = Timestamp.today()\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return X.apply(lambda x: (x - self.today).dt.days, axis=0)\n",
        "\n",
        "# Centers and reduces (variance=1) columns\n",
        "standard_scaler = StandardScaler()\n",
        "\n",
        "# One-hot encode, similar to pd.get_dummies\n",
        "# one_hot_encoder = OneHotEncoder(drop='first', sparse=False)\n",
        "\n",
        "# A pipeline that first computes age, and standardizes it\n",
        "scaled_age_encoder = Pipeline([\n",
        "    ('age', AgeEncoder()),\n",
        "    ('scaling', StandardScaler())\n",
        "])\n",
        "\n",
        "# Let's combine all these transformations\n",
        "transformer = ColumnTransformer([\n",
        "    ('standard_scaling', standard_scaler, cnt_featnames),\n",
        "    ('dates_age_scaled', scaled_age_encoder, date_featnames)\n",
        "])\n",
        "\n",
        "data_prep = transformer.fit_transform(data)\n",
        "\n",
        "##turn the neww array into dataframe\n",
        "data_prep = pd.DataFrame(data_prep, columns=['length', 'weight', 'count', 'looped', 'neighbors', 'income', 'time'])\n",
        "data_prep['label'] = Y\n",
        "\n",
        "##save as pickle\n",
        "data_prep.to_pickle(\"data_prep_df.pkl\")"
      ],
      "metadata": {
        "id": "xlhEWqHR-tBm"
      },
      "execution_count": 36,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Construction feature extractor.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}